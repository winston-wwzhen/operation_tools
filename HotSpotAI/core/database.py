"""
å¼‚æ­¥æ•°æ®åº“ç®¡ç†æ¨¡å—
ä½¿ç”¨è¿æ¥æ± æä¾›éé˜»å¡çš„æ•°æ®åº“æ“ä½œ
"""
import aiosqlite
import json
from datetime import datetime
from typing import List, Dict, Optional
from core.config import add_log
from core.db_pool import get_db

DB_FILE = "data.db"


async def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„ï¼ˆå¼‚æ­¥ï¼‰"""
    try:
        async with get_db() as db:
            # çƒ­ç‚¹è¯é¢˜è¡¨ - ç²¾é€‰åçš„æœ€ç»ˆçƒ­ç‚¹
            await db.execute('''
                CREATE TABLE IF NOT EXISTS hot_topics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    link TEXT NOT NULL,
                    source TEXT NOT NULL,
                    ai_score DECIMAL(3,2),
                    ai_comment TEXT,
                    category_id INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (category_id) REFERENCES categories(id)
                )
            ''')

            # ç”¨æˆ·è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT UNIQUE NOT NULL,
                    email TEXT UNIQUE NOT NULL,
                    password_hash TEXT NOT NULL,
                    is_admin INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')

            # ç”¨æˆ·æ–‡ç« è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS user_articles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    topic_id INTEGER,
                    topic_title TEXT NOT NULL,
                    topic_link TEXT,
                    topic_source TEXT,
                    title TEXT NOT NULL,
                    content TEXT NOT NULL,
                    platform TEXT NOT NULL,
                    share_token TEXT UNIQUE NOT NULL,
                    is_public INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
                )
            ''')

            # åˆ›å»ºç´¢å¼•ä»¥æå‡æŸ¥è¯¢æ€§èƒ½
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_created_at
                ON hot_topics(created_at DESC)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_source
                ON hot_topics(source)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_users_username
                ON users(username)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_users_email
                ON users(email)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_user_articles_user_id
                ON user_articles(user_id)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_user_articles_share_token
                ON user_articles(share_token)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_user_articles_created_at
                ON user_articles(created_at DESC)
            ''')

            # åˆ›å»ºæ›´æ–°æ—¶é—´è§¦å‘å™¨
            await db.execute('''
                CREATE TRIGGER IF NOT EXISTS update_users_timestamp
                AFTER UPDATE ON users
                BEGIN
                    UPDATE users SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
                END
            ''')
            await db.execute('''
                CREATE TRIGGER IF NOT EXISTS update_user_articles_timestamp
                AFTER UPDATE ON user_articles
                BEGIN
                    UPDATE user_articles SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
                END
            ''')

            # å¾®ä¿¡å…¬ä¼—å·è´¦å·é…ç½®è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS wechat_accounts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    app_id TEXT NOT NULL,
                    secret TEXT NOT NULL,
                    account_name TEXT,
                    nickname TEXT,
                    avatar_url TEXT,
                    access_token TEXT,
                    token_expires_at INTEGER,
                    is_active INTEGER DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
                )
            ''')

            # å¾®ä¿¡å‘å¸ƒè®°å½•è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS wechat_publish_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    article_id INTEGER NOT NULL,
                    wechat_account_id INTEGER NOT NULL,
                    publish_type TEXT NOT NULL,
                    media_id TEXT,
                    publish_status TEXT DEFAULT 'pending',
                    publish_id TEXT,
                    published_at TIMESTAMP,
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    FOREIGN KEY (article_id) REFERENCES user_articles(id) ON DELETE CASCADE,
                    FOREIGN KEY (wechat_account_id) REFERENCES wechat_accounts(id) ON DELETE CASCADE
                )
            ''')

            # å¾®ä¿¡è´¦å·è¡¨ç´¢å¼•
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_wechat_accounts_user_id
                ON wechat_accounts(user_id)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_wechat_accounts_is_active
                ON wechat_accounts(is_active)
            ''')

            # å‘å¸ƒè®°å½•è¡¨ç´¢å¼•
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_wechat_publish_log_user_id
                ON wechat_publish_log(user_id)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_wechat_publish_log_article_id
                ON wechat_publish_log(article_id)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_wechat_publish_log_created_at
                ON wechat_publish_log(created_at DESC)
            ''')

            # åˆ›å»ºå¾®ä¿¡è´¦å·è¡¨æ›´æ–°æ—¶é—´è§¦å‘å™¨
            await db.execute('''
                CREATE TRIGGER IF NOT EXISTS update_wechat_accounts_timestamp
                AFTER UPDATE ON wechat_accounts
                BEGIN
                    UPDATE wechat_accounts SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
                END
            ''')

            # ========== åˆ†ç±»ç›¸å…³è¡¨ ==========

            # åˆ†ç±»è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS categories (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT UNIQUE NOT NULL,
                    slug TEXT UNIQUE NOT NULL,
                    description TEXT,
                    icon TEXT,
                    color TEXT,
                    is_active INTEGER DEFAULT 1,
                    sort_order INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')

            # å…³é”®è¯è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS category_keywords (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    category_id INTEGER NOT NULL,
                    keyword TEXT NOT NULL,
                    weight INTEGER DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (category_id) REFERENCES categories(id) ON DELETE CASCADE
                )
            ''')

            # å¹³å°åˆ†ç±»é…ç½®è¡¨
            await db.execute('''
                CREATE TABLE IF NOT EXISTS category_platforms (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    category_id INTEGER NOT NULL,
                    platform TEXT NOT NULL,
                    is_enabled INTEGER DEFAULT 1,
                    FOREIGN KEY (category_id) REFERENCES categories(id) ON DELETE CASCADE
                )
            ''')

            # åˆ†ç±»ç›¸å…³ç´¢å¼•
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_category_keywords_category_id
                ON category_keywords(category_id)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_category_keywords_keyword
                ON category_keywords(keyword)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_category_platforms_category_id
                ON category_platforms(category_id)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_categories_is_active
                ON categories(is_active)
            ''')

            # åˆ›å»ºåˆ†ç±»è¡¨æ›´æ–°æ—¶é—´è§¦å‘å™¨
            await db.execute('''
                CREATE TRIGGER IF NOT EXISTS update_categories_timestamp
                AFTER UPDATE ON categories
                BEGIN
                    UPDATE categories SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
                END
            ''')

            # ========== åŸå§‹æ–°é—»è¡¨ï¼ˆraw_newsï¼‰ç”¨äºçˆ¬è™«å­˜å‚¨ ==========
            await db.execute('''
                CREATE TABLE IF NOT EXISTS raw_news (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    link TEXT UNIQUE NOT NULL,
                    source TEXT NOT NULL,
                    category_id INTEGER,
                    analyzed BOOLEAN DEFAULT 0,
                    analyze_fail_count INTEGER DEFAULT 0,
                    skip_reason TEXT,
                    ai_score DECIMAL(3,2),
                    ai_comment TEXT,
                    last_analyzed_at TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (category_id) REFERENCES categories(id)
                )
            ''')

            # raw_news ç´¢å¼•
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_raw_news_link ON raw_news(link)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_raw_news_source ON raw_news(source)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_raw_news_analyzed ON raw_news(analyzed)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_raw_news_created_at ON raw_news(created_at DESC)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_raw_news_ai_score ON raw_news(ai_score DESC)
            ''')
            await db.execute('''
                CREATE INDEX IF NOT EXISTS idx_raw_news_category_id ON raw_news(category_id)
            ''')

            await db.commit()

            # æ•°æ®åº“è¿ç§»ï¼šä¸ºå·²å­˜åœ¨çš„ users è¡¨æ·»åŠ  is_admin å­—æ®µ
            try:
                await db.execute('ALTER TABLE users ADD COLUMN is_admin INTEGER DEFAULT 0')
                await db.commit()
                add_log('info', 'æ•°æ®åº“è¿ç§»å®Œæˆï¼šå·²æ·»åŠ  is_admin å­—æ®µ')
            except Exception as migrate_error:
                # å­—æ®µå·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                if 'duplicate column' not in str(migrate_error).lower():
                    pass

            # æ•°æ®åº“è¿ç§»ï¼šä¸ºå·²å­˜åœ¨çš„ user_articles è¡¨æ·»åŠ å¾®ä¿¡ç›¸å…³å­—æ®µ
            try:
                await db.execute('ALTER TABLE user_articles ADD COLUMN wechat_draft_id TEXT')
                await db.execute('ALTER TABLE user_articles ADD COLUMN wechat_publish_status TEXT DEFAULT "draft"')
                await db.commit()
                add_log('info', 'æ•°æ®åº“è¿ç§»å®Œæˆï¼šå·²æ·»åŠ å¾®ä¿¡ç›¸å…³å­—æ®µ')
            except Exception as migrate_error:
                # å­—æ®µå·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                if 'duplicate column' not in str(migrate_error).lower():
                    pass

            # æ•°æ®åº“è¿ç§»ï¼šä¸º hot_topics è¡¨æ·»åŠ åˆ†ç±»ç›¸å…³å­—æ®µ
            try:
                await db.execute('ALTER TABLE hot_topics ADD COLUMN category_id INTEGER')
                await db.execute('ALTER TABLE hot_topics ADD COLUMN matched_keyword TEXT')
                await db.execute('CREATE INDEX IF NOT EXISTS idx_hot_topics_category_id ON hot_topics(category_id)')
                await db.commit()
                add_log('info', 'æ•°æ®åº“è¿ç§»å®Œæˆï¼šå·²æ·»åŠ åˆ†ç±»ç›¸å…³å­—æ®µ')
            except Exception as migrate_error:
                # å­—æ®µå·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                if 'duplicate column' not in str(migrate_error).lower():
                    pass

        add_log('info', 'æ•°æ®åº“åˆå§‹åŒ–æ£€æŸ¥å®Œæˆ')
    except Exception as e:
        add_log('error', f'æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}')


async def save_topics_to_db(topics: List[Dict]) -> int:
    """
    ä¿å­˜ä¸€æ‰¹çƒ­ç‚¹æ•°æ®ï¼ˆå¼‚æ­¥ï¼‰

    Args:
        topics: çƒ­ç‚¹è¯é¢˜åˆ—è¡¨ï¼Œæ”¯æŒæ‰©å±•å­—æ®µ category_id å’Œ matched_keyword

    Returns:
        ä¿å­˜çš„è®°å½•æ•°
    """
    if not topics:
        return 0

    try:
        async with get_db() as db:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            count = 0

            # ä½¿ç”¨äº‹åŠ¡æ‰¹é‡æ’å…¥
            async with db.execute('BEGIN') as _:
                for topic in topics:
                    tags_json = json.dumps(topic.get('tags', []), ensure_ascii=False)

                    await db.execute('''
                        INSERT INTO hot_topics (title, link, source, heat, tags, comment, created_at, category_id, matched_keyword)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        topic.get('title'),
                        topic.get('link'),
                        topic.get('source'),
                        topic.get('heat', 0),
                        tags_json,
                        topic.get('comment', ''),
                        timestamp,
                        topic.get('category_id'),
                        topic.get('matched_keyword')
                    ))
                    count += 1

                await db.commit()

        add_log('success', f'å·²å°† {count} æ¡æ•°æ®ä¿å­˜è‡³æ•°æ®åº“')
        return count

    except Exception as e:
        add_log('error', f'ä¿å­˜æ•°æ®è‡³æ•°æ®åº“å¤±è´¥: {e}')
        return 0


async def load_latest_topics_from_db(limit: int = 50) -> List[Dict]:
    """
    åŠ è½½æœ€è¿‘ä¸€æ¬¡æŠ“å–çš„æ•°æ®ï¼ˆå¼‚æ­¥ï¼‰

    Args:
        limit: æœ€å¤§è¿”å›æ•°é‡

    Returns:
        çƒ­ç‚¹è¯é¢˜åˆ—è¡¨
    """
    topics = []
    try:
        async with get_db() as db:

            # æŸ¥æœ€è¿‘çš„æ—¶é—´ç‚¹
            async with db.execute(
                "SELECT created_at FROM hot_topics ORDER BY id DESC LIMIT 1"
            ) as cursor:
                row = await cursor.fetchone()

            if row:
                latest_time = row['created_at']

                # æŸ¥è¯¥æ—¶é—´ç‚¹çš„æ‰€æœ‰æ•°æ®
                async with db.execute('''
                    SELECT * FROM hot_topics
                    WHERE created_at = ?
                    ORDER BY heat DESC
                    LIMIT ?
                ''', (latest_time, limit)) as cursor:
                    rows = await cursor.fetchall()

                for r in rows:
                    topics.append({
                        "title": r['title'],
                        "link": r['link'],
                        "source": r['source'],
                        "heat": r['heat'],
                        "tags": json.loads(r['tags']) if r['tags'] else [],
                        "comment": r['comment']
                    })

                add_log('info', f'ä»æ•°æ®åº“æ¢å¤äº† {len(topics)} æ¡å†å²è®°å½• ({latest_time})')

    except Exception as e:
        add_log('error', f'è¯»å–æ•°æ®åº“å¤±è´¥: {e}')

    return topics


async def get_topics_by_source(source: str, limit: int = 20) -> List[Dict]:
    """
    æŒ‰æ¥æºè·å–çƒ­ç‚¹è¯é¢˜ï¼ˆå¼‚æ­¥ï¼‰

    Args:
        source: æ•°æ®æº (weibo, baidu, zhihuç­‰)
        limit: æœ€å¤§è¿”å›æ•°é‡

    Returns:
        çƒ­ç‚¹è¯é¢˜åˆ—è¡¨
    """
    topics = []
    try:
        async with get_db() as db:

            async with db.execute('''
                SELECT * FROM hot_topics
                WHERE source = ?
                ORDER BY heat DESC
                LIMIT ?
            ''', (source, limit)) as cursor:
                rows = await cursor.fetchall()

            for r in rows:
                topics.append({
                    "title": r['title'],
                    "link": r['link'],
                    "source": r['source'],
                    "heat": r['heat'],
                    "tags": json.loads(r['tags']) if r['tags'] else [],
                    "comment": r['comment']
                })

    except Exception as e:
        add_log('error', f'æŒ‰æ¥æºè¯»å–æ•°æ®åº“å¤±è´¥: {e}')

    return topics


async def clean_old_topics(days: int = 7) -> int:
    """
    æ¸…ç†æ—§æ•°æ®ï¼ˆå¼‚æ­¥ï¼‰

    Args:
        days: ä¿ç•™æœ€è¿‘å‡ å¤©çš„æ•°æ®

    Returns:
        åˆ é™¤çš„è®°å½•æ•°
    """
    try:
        async with get_db() as db:
            cursor = await db.execute('''
                DELETE FROM hot_topics
                WHERE created_at < datetime('now', '-' || ? || ' days')
            ''', (days,))
            await db.commit()

            deleted_count = cursor.rowcount
            if deleted_count > 0:
                add_log('info', f'å·²æ¸…ç† {deleted_count} æ¡ {days} å¤©å‰çš„æ—§æ•°æ®')

            return deleted_count

    except Exception as e:
        add_log('error', f'æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}')
        return 0


async def get_stats() -> Dict:
    """
    è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼‰

    Returns:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    stats = {
        "total_topics": 0,
        "by_source": {},
        "latest_update": None
    }

    try:
        async with get_db() as db:
            # æ€»æ•°ç»Ÿè®¡
            async with db.execute("SELECT COUNT(*) as count FROM hot_topics") as cursor:
                row = await cursor.fetchone()
                stats["total_topics"] = row["count"]

            # æŒ‰æ¥æºç»Ÿè®¡
            async with db.execute('''
                SELECT source, COUNT(*) as count
                FROM hot_topics
                GROUP BY source
            ''') as cursor:
                rows = await cursor.fetchall()
                for r in rows:
                    stats["by_source"][r["source"]] = r["count"]

            # æœ€æ–°æ›´æ–°æ—¶é—´
            async with db.execute('''
                SELECT created_at FROM hot_topics
                ORDER BY id DESC LIMIT 1
            ''') as cursor:
                row = await cursor.fetchone()
                if row:
                    stats["latest_update"] = row["created_at"]

    except Exception as e:
        add_log('error', f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}')

    return stats


async def get_historical_topics(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    source: Optional[str] = None,
    offset: int = 0,
    limit: int = 50
) -> Dict:
    """
    è·å–å†å²çƒ­ç‚¹æ•°æ®ï¼ˆæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼‰

    Args:
        start_date: èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        source: æ•°æ®æºç­›é€‰ (weibo, baidu, zhihuç­‰)
        offset: åç§»é‡ï¼ˆç”¨äºåˆ†é¡µï¼‰
        limit: æ¯é¡µæ•°é‡

    Returns:
        {
            "topics": [...],
            "total": æ€»æ•°,
            "offset": åç§»é‡,
            "limit": æ¯é¡µæ•°é‡
        }
    """
    topics = []
    total = 0

    try:
        async with get_db() as db:

            # æ„å»º WHERE æ¡ä»¶
            where_conditions = []
            params = []

            if start_date:
                where_conditions.append("DATE(created_at) >= ?")
                params.append(start_date)
            if end_date:
                where_conditions.append("DATE(created_at) <= ?")
                params.append(end_date)
            if source:
                where_conditions.append("source = ?")
                params.append(source)

            where_clause = ""
            if where_conditions:
                where_clause = "WHERE " + " AND ".join(where_conditions)

            # è·å–æ€»æ•°
            count_params = params.copy()
            async with db.execute(
                f"SELECT COUNT(*) as count FROM hot_topics {where_clause}",
                count_params
            ) as cursor:
                row = await cursor.fetchone()
                total = row["count"]

            # è·å–åˆ†é¡µæ•°æ®
            query_params = params.copy()
            query_params.extend([limit, offset])
            async with db.execute(f'''
                SELECT * FROM hot_topics
                {where_clause}
                ORDER BY created_at DESC, heat DESC
                LIMIT ? OFFSET ?
            ''', query_params) as cursor:
                rows = await cursor.fetchall()

            for r in rows:
                topics.append({
                    "id": r['id'],
                    "title": r['title'],
                    "link": r['link'],
                    "source": r['source'],
                    "heat": r['heat'],
                    "tags": json.loads(r['tags']) if r['tags'] else [],
                    "comment": r['comment'],
                    "created_at": r['created_at']
                })

    except Exception as e:
        add_log('error', f'è·å–å†å²æ•°æ®å¤±è´¥: {e}')

    return {
        "topics": topics,
        "total": total,
        "offset": offset,
        "limit": limit
    }


async def get_distinct_dates() -> List[str]:
    """
    è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æœ‰æ•°æ®çš„æ—¥æœŸåˆ—è¡¨

    Returns:
        æ—¥æœŸåˆ—è¡¨ (YYYY-MM-DD æ ¼å¼ï¼Œé™åº)
    """
    dates = []
    try:
        async with get_db() as db:
            async with db.execute('''
                SELECT DISTINCT DATE(created_at) as date
                FROM hot_topics
                ORDER BY date DESC
            ''') as cursor:
                rows = await cursor.fetchall()
                for r in rows:
                    dates.append(r['date'])

    except Exception as e:
        add_log('error', f'è·å–æ—¥æœŸåˆ—è¡¨å¤±è´¥: {e}')

    return dates


# ============ åˆ†ç±»ç›¸å…³å‡½æ•° ============

# é¢„å®šä¹‰åˆ†ç±»æ•°æ®
DEFAULT_CATEGORIES = [
    {
        "name": "AIç§‘æŠ€",
        "slug": "ai-tech",
        "description": "äººå·¥æ™ºèƒ½ã€å‰æ²¿ç§‘æŠ€",
        "icon": "ğŸ¤–",
        "color": "#6366f1",
        "keywords": ["AI", "ChatGPT", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "èŠ¯ç‰‡", "åŠå¯¼ä½“", "5G", "åŒºå—é“¾"]
    },
    {
        "name": "è´¢ç»æŠ•èµ„",
        "slug": "finance",
        "description": "é‡‘èã€æŠ•èµ„ã€è‚¡å¸‚",
        "icon": "ğŸ’°",
        "color": "#10b981",
        "keywords": ["è‚¡ç¥¨", "åŸºé‡‘", "ç†è´¢", "Aè‚¡", "æ¸¯è‚¡", "ç¾è‚¡", "æ¯”ç‰¹å¸", "é‡‘è"]
    },
    {
        "name": "èŒåœºæˆé•¿",
        "slug": "career",
        "description": "èŒä¸šå‘å±•ã€æŠ€èƒ½æå‡",
        "icon": "ğŸ’¼",
        "color": "#f59e0b",
        "keywords": ["èŒåœº", "é¢è¯•", "è–ªèµ„", "è£å‘˜", "è·³æ§½", "è€ƒè¯", "å‰¯ä¸š", "åˆ›ä¸š"]
    },
    {
        "name": "å¥åº·å…»ç”Ÿ",
        "slug": "health",
        "description": "å¥åº·ã€åŒ»ç–—ã€å…»ç”Ÿ",
        "icon": "ğŸ¥",
        "color": "#ef4444",
        "keywords": ["å¥åº·", "åŒ»ç–—", "å…»ç”Ÿ", "å‡è‚¥", "å¥èº«", "ç–«è‹—", "åŒ»ä¿", "ç–«æƒ…"]
    },
    {
        "name": "æ•™è‚²è‚²å„¿",
        "slug": "education",
        "description": "æ•™è‚²ã€è‚²å„¿ã€å­¦ä¹ ",
        "icon": "ğŸ“š",
        "color": "#8b5cf6",
        "keywords": ["æ•™è‚²", "é«˜è€ƒ", "è€ƒç ”", "ç•™å­¦", "è‚²å„¿", "åŒå‡", "åŸ¹è®­", "å¹¼å‡å°"]
    },
    {
        "name": "æ•°ç è¯„æµ‹",
        "slug": "digital",
        "description": "æ•°ç äº§å“ã€è¯„æµ‹",
        "icon": "ğŸ“±",
        "color": "#3b82f6",
        "keywords": ["æ‰‹æœº", "ç”µè„‘", "å¹³æ¿", "è€³æœº", "ç›¸æœº", "æµ‹è¯„", "å‘å¸ƒä¼š", "æ–°å“"]
    },
    {
        "name": "ç¾é£Ÿç”Ÿæ´»",
        "slug": "food",
        "description": "ç¾é£Ÿã€ç”Ÿæ´»æ–¹å¼",
        "icon": "ğŸœ",
        "color": "#f97316",
        "keywords": ["ç¾é£Ÿ", "èœè°±", "é¤å…", "æ¢åº—", "å¤–å–", "å’–å•¡", "å¥¶èŒ¶", "é›¶é£Ÿ"]
    },
    {
        "name": "å½±è§†å¨±ä¹",
        "slug": "entertainment",
        "description": "å½±è§†ã€ç»¼è‰ºã€å¨±ä¹",
        "icon": "ğŸ¬",
        "color": "#ec4899",
        "keywords": ["ç”µå½±", "ç”µè§†å‰§", "ç»¼è‰º", "æ˜æ˜Ÿ", "å¨±ä¹åœˆ", "ç¥¨æˆ¿", "å‰§é›†", "æ¡£æœŸ"]
    },
    {
        "name": "æ—…æ¸¸å‡ºè¡Œ",
        "slug": "travel",
        "description": "æ—…æ¸¸ã€äº¤é€šã€å‡ºè¡Œ",
        "icon": "âœˆï¸",
        "color": "#06b6d4",
        "keywords": ["æ—…æ¸¸", "æœºç¥¨", "é…’åº—", "æ™¯ç‚¹", "è‡ªé©¾", "å‡æœŸ", "äº¤é€š", "å‡ºè¡Œ"]
    },
    {
        "name": "æƒ…æ„Ÿå¿ƒç†",
        "slug": "emotion",
        "description": "æƒ…æ„Ÿã€å¿ƒç†ã€äººé™…å…³ç³»",
        "icon": "ğŸ’•",
        "color": "#d946ef",
        "keywords": ["æ‹çˆ±", "å©šå§»", "æƒ…æ„Ÿ", "å¿ƒç†", "æŠ‘éƒ", "ç„¦è™‘", "ç¤¾äº¤", "äººé™…å…³ç³»"]
    }
]


async def get_categories(include_inactive: bool = False) -> List[Dict]:
    """
    è·å–æ‰€æœ‰åˆ†ç±»

    Args:
        include_inactive: æ˜¯å¦åŒ…å«æœªæ¿€æ´»çš„åˆ†ç±»

    Returns:
        åˆ†ç±»åˆ—è¡¨
    """
    categories = []
    try:
        async with get_db() as db:
            

            where_clause = "" if include_inactive else "WHERE is_active = 1"

            async with db.execute(f'''
                SELECT id, name, slug, description, icon, color, is_active, sort_order, created_at, updated_at
                FROM categories
                {where_clause}
                ORDER BY sort_order ASC, id ASC
            ''') as cursor:
                rows = await cursor.fetchall()

            for r in rows:
                categories.append({
                    "id": r['id'],
                    "name": r['name'],
                    "slug": r['slug'],
                    "description": r['description'],
                    "icon": r['icon'],
                    "color": r['color'],
                    "is_active": bool(r['is_active']),
                    "sort_order": r['sort_order'],
                    "created_at": r['created_at'],
                    "updated_at": r['updated_at']
                })

    except Exception as e:
        add_log('error', f'è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥: {e}')

    return categories


async def get_category_by_id(category_id: int) -> Optional[Dict]:
    """
    è·å–åˆ†ç±»è¯¦æƒ…ï¼ˆå«å…³é”®è¯å’Œå¹³å°é…ç½®ï¼‰

    Args:
        category_id: åˆ†ç±»ID

    Returns:
        åˆ†ç±»è¯¦æƒ…ï¼ŒåŒ…å«å…³é”®è¯åˆ—è¡¨å’Œå¹³å°é…ç½®
    """
    try:
        async with get_db() as db:
            

            # è·å–åˆ†ç±»åŸºæœ¬ä¿¡æ¯
            async with db.execute('''
                SELECT id, name, slug, description, icon, color, is_active, sort_order, created_at, updated_at
                FROM categories
                WHERE id = ?
            ''', (category_id,)) as cursor:
                row = await cursor.fetchone()

            if not row:
                return None

            category = {
                "id": row['id'],
                "name": row['name'],
                "slug": row['slug'],
                "description": row['description'],
                "icon": row['icon'],
                "color": row['color'],
                "is_active": bool(row['is_active']),
                "sort_order": row['sort_order'],
                "created_at": row['created_at'],
                "updated_at": row['updated_at'],
                "keywords": [],
                "platforms": []
            }

            # è·å–å…³é”®è¯
            async with db.execute('''
                SELECT keyword, weight
                FROM category_keywords
                WHERE category_id = ?
                ORDER BY weight DESC, id ASC
            ''', (category_id,)) as cursor:
                keyword_rows = await cursor.fetchall()
                for kr in keyword_rows:
                    category["keywords"].append({
                        "keyword": kr['keyword'],
                        "weight": kr['weight']
                    })

            # è·å–å¹³å°é…ç½®
            async with db.execute('''
                SELECT platform, is_enabled
                FROM category_platforms
                WHERE category_id = ?
            ''', (category_id,)) as cursor:
                platform_rows = await cursor.fetchall()
                for pr in platform_rows:
                    category["platforms"].append({
                        "platform": pr['platform'],
                        "is_enabled": bool(pr['is_enabled'])
                    })

            return category

    except Exception as e:
        add_log('error', f'è·å–åˆ†ç±»è¯¦æƒ…å¤±è´¥: {e}')
        return None


async def get_categories_with_keywords() -> List[Dict]:
    """
    è·å–æ‰€æœ‰åˆ†ç±»åŠå…¶å…³é”®è¯ï¼ˆç”¨äºæŠ“å–ä»»åŠ¡ï¼‰

    Returns:
        åˆ†ç±»åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ†ç±»åŒ…å«å…³é”®è¯
    """
    categories = []
    try:
        async with get_db() as db:
            

            async with db.execute('''
                SELECT id, name, slug, is_active
                FROM categories
                WHERE is_active = 1
                ORDER BY sort_order ASC, id ASC
            ''') as cursor:
                rows = await cursor.fetchall()

            for r in rows:
                category = {
                    "id": r['id'],
                    "name": r['name'],
                    "slug": r['slug'],
                    "keywords": []
                }

                # è·å–å…³é”®è¯
                async with db.execute('''
                    SELECT keyword
                    FROM category_keywords
                    WHERE category_id = ?
                    ORDER BY weight DESC, id ASC
                ''', (r['id'],)) as keyword_cursor:
                    keyword_rows = await keyword_cursor.fetchall()
                    category["keywords"] = [kr['keyword'] for kr in keyword_rows]

                categories.append(category)

    except Exception as e:
        add_log('error', f'è·å–åˆ†ç±»å’Œå…³é”®è¯å¤±è´¥: {e}')

    return categories


async def create_category(data: Dict) -> int:
    """
    åˆ›å»ºåˆ†ç±»

    Args:
        data: åˆ†ç±»æ•°æ®ï¼ŒåŒ…å« name, slug, description, icon, color, keywords, platforms

    Returns:
        æ–°åˆ›å»ºçš„åˆ†ç±»ID
    """
    try:
        async with get_db() as db:
            # æ’å…¥åˆ†ç±»
            await db.execute('''
                INSERT INTO categories (name, slug, description, icon, color, is_active, sort_order)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                data.get('name'),
                data.get('slug'),
                data.get('description'),
                data.get('icon'),
                data.get('color'),
                data.get('is_active', True),
                data.get('sort_order', 0)
            ))

            # è·å–æ–°æ’å…¥çš„ID
            async with db.execute("SELECT last_insert_rowid() as id") as cursor:
                row = await cursor.fetchone()
                category_id = row["id"]

            # æ’å…¥å…³é”®è¯
            if data.get('keywords'):
                for keyword in data['keywords']:
                    await db.execute('''
                        INSERT INTO category_keywords (category_id, keyword, weight)
                        VALUES (?, ?, ?)
                    ''', (category_id, keyword, 1))

            # æ’å…¥å¹³å°é…ç½®
            if data.get('platforms'):
                for platform in data['platforms']:
                    await db.execute('''
                        INSERT INTO category_platforms (category_id, platform, is_enabled)
                        VALUES (?, ?, ?)
                    ''', (category_id, platform, 1))

            await db.commit()
            add_log('success', f'åˆ›å»ºåˆ†ç±»æˆåŠŸ: {data.get("name")}')
            return category_id

    except Exception as e:
        add_log('error', f'åˆ›å»ºåˆ†ç±»å¤±è´¥: {e}')
        raise


async def update_category(category_id: int, data: Dict) -> bool:
    """
    æ›´æ–°åˆ†ç±»

    Args:
        category_id: åˆ†ç±»ID
        data: è¦æ›´æ–°çš„æ•°æ®

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        async with get_db() as db:
            # æ„å»ºæ›´æ–°SQL
            update_fields = []
            update_values = []

            for field in ['name', 'slug', 'description', 'icon', 'color', 'is_active', 'sort_order']:
                if field in data:
                    update_fields.append(f"{field} = ?")
                    update_values.append(data[field])

            if update_fields:
                update_values.append(category_id)
                await db.execute(f'''
                    UPDATE categories
                    SET {', '.join(update_fields)}
                    WHERE id = ?
                ''', update_values)

            await db.commit()
            add_log('success', f'æ›´æ–°åˆ†ç±»æˆåŠŸ: {category_id}')
            return True

    except Exception as e:
        add_log('error', f'æ›´æ–°åˆ†ç±»å¤±è´¥: {e}')
        return False


async def delete_category(category_id: int) -> bool:
    """
    åˆ é™¤åˆ†ç±»

    Args:
        category_id: åˆ†ç±»ID

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        async with get_db() as db:
            # åˆ é™¤å…³é”®è¯ï¼ˆçº§è”åˆ é™¤ï¼‰
            await db.execute('DELETE FROM category_keywords WHERE category_id = ?', (category_id,))

            # åˆ é™¤å¹³å°é…ç½®ï¼ˆçº§è”åˆ é™¤ï¼‰
            await db.execute('DELETE FROM category_platforms WHERE category_id = ?', (category_id,))

            # åˆ é™¤åˆ†ç±»
            await db.execute('DELETE FROM categories WHERE id = ?', (category_id,))

            await db.commit()
            add_log('success', f'åˆ é™¤åˆ†ç±»æˆåŠŸ: {category_id}')
            return True

    except Exception as e:
        add_log('error', f'åˆ é™¤åˆ†ç±»å¤±è´¥: {e}')
        return False


async def update_category_keywords(category_id: int, keywords: List[str]) -> bool:
    """
    æ›´æ–°åˆ†ç±»å…³é”®è¯

    Args:
        category_id: åˆ†ç±»ID
        keywords: å…³é”®è¯åˆ—è¡¨

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        async with get_db() as db:
            # åˆ é™¤æ—§å…³é”®è¯
            await db.execute('DELETE FROM category_keywords WHERE category_id = ?', (category_id,))

            # æ’å…¥æ–°å…³é”®è¯
            for keyword in keywords:
                await db.execute('''
                    INSERT INTO category_keywords (category_id, keyword, weight)
                    VALUES (?, ?, ?)
                ''', (category_id, keyword, 1))

            await db.commit()
            add_log('success', f'æ›´æ–°åˆ†ç±»å…³é”®è¯æˆåŠŸ: {category_id}')
            return True

    except Exception as e:
        add_log('error', f'æ›´æ–°åˆ†ç±»å…³é”®è¯å¤±è´¥: {e}')
        return False


async def update_category_platforms(category_id: int, platforms: List[str]) -> bool:
    """
    æ›´æ–°åˆ†ç±»å¹³å°é…ç½®

    Args:
        category_id: åˆ†ç±»ID
        platforms: å¯ç”¨çš„å¹³å°åˆ—è¡¨

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        async with get_db() as db:
            # åˆ é™¤æ—§é…ç½®
            await db.execute('DELETE FROM category_platforms WHERE category_id = ?', (category_id,))

            # æ’å…¥æ–°é…ç½®
            for platform in platforms:
                await db.execute('''
                    INSERT INTO category_platforms (category_id, platform, is_enabled)
                    VALUES (?, ?, ?)
                ''', (category_id, platform, 1))

            await db.commit()
            return True

    except Exception as e:
        add_log('error', f'æ›´æ–°åˆ†ç±»å¹³å°å¤±è´¥: {e}')
        return False


async def get_category_platforms(category_id: int) -> List[Dict]:
    """
    è·å–åˆ†ç±»çš„å¹³å°é…ç½®

    Args:
        category_id: åˆ†ç±»ID

    Returns:
        å¹³å°åˆ—è¡¨
    """
    platforms = []
    try:
        async with get_db() as db:
            
            async with db.execute('''
                SELECT platform, is_enabled FROM category_platforms
                WHERE category_id = ?
            ''', (category_id,)) as cursor:
                rows = await cursor.fetchall()
                platforms = [dict(r) for r in rows]

    except Exception as e:
        add_log('error', f'è·å–åˆ†ç±»å¹³å°å¤±è´¥: {e}')

    return platforms


async def init_default_categories() -> int:
    """
    åˆå§‹åŒ–é»˜è®¤åˆ†ç±»

    Returns:
        åˆ›å»ºçš„åˆ†ç±»æ•°é‡
    """
    try:
        async with get_db() as db:
            created_count = 0
            default_platforms = ['weibo', 'zhihu', 'douyin', 'xiaohongshu', 'toutiao']

            for cat_data in DEFAULT_CATEGORIES:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                
                async with db.execute(
                    "SELECT id FROM categories WHERE slug = ?",
                    (cat_data['slug'],)
                ) as cursor:
                    existing = await cursor.fetchone()

                if existing:
                    continue

                # æ’å…¥åˆ†ç±»
                await db.execute('''
                    INSERT INTO categories (name, slug, description, icon, color, is_active, sort_order)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    cat_data['name'],
                    cat_data['slug'],
                    cat_data['description'],
                    cat_data['icon'],
                    cat_data['color'],
                    1,
                    created_count
                ))

                # è·å–æ–°æ’å…¥çš„ID
                async with db.execute("SELECT last_insert_rowid() as id") as cursor:
                    row = await cursor.fetchone()
                    category_id = row["id"]

                # æ’å…¥å…³é”®è¯
                for keyword in cat_data['keywords']:
                    await db.execute('''
                        INSERT INTO category_keywords (category_id, keyword, weight)
                        VALUES (?, ?, ?)
                    ''', (category_id, keyword, 1))

                # æ’å…¥å¹³å°é…ç½®
                for platform in default_platforms:
                    await db.execute('''
                        INSERT INTO category_platforms (category_id, platform, is_enabled)
                        VALUES (?, ?, ?)
                    ''', (category_id, platform, 1))

                created_count += 1

            await db.commit()

            if created_count > 0:
                add_log('success', f'åˆå§‹åŒ–é»˜è®¤åˆ†ç±»å®Œæˆï¼Œå…±åˆ›å»º {created_count} ä¸ªåˆ†ç±»')
            else:
                add_log('info', 'é»˜è®¤åˆ†ç±»å·²å­˜åœ¨ï¼Œæ— éœ€åˆå§‹åŒ–')

            return created_count

    except Exception as e:
        add_log('error', f'åˆå§‹åŒ–é»˜è®¤åˆ†ç±»å¤±è´¥: {e}')
        return 0


async def get_topics_by_category(
    category_id: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    source: Optional[str] = None,
    offset: int = 0,
    limit: int = 50
) -> Dict:
    """
    æŒ‰åˆ†ç±»è·å–çƒ­ç‚¹è¯é¢˜

    Args:
        category_id: åˆ†ç±»IDï¼ˆå¯é€‰ï¼‰
        start_date: èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        source: æ•°æ®æºç­›é€‰
        offset: åç§»é‡
        limit: æ¯é¡µæ•°é‡

    Returns:
        {
            "topics": [...],
            "total": æ€»æ•°,
            "offset": åç§»é‡,
            "limit": æ¯é¡µæ•°é‡
        }
    """
    topics = []
    total = 0

    try:
        async with get_db() as db:
            

            # æ„å»º WHERE æ¡ä»¶
            where_conditions = []
            params = []

            if category_id:
                where_conditions.append("category_id = ?")
                params.append(category_id)
            if start_date:
                where_conditions.append("DATE(created_at) >= ?")
                params.append(start_date)
            if end_date:
                where_conditions.append("DATE(created_at) <= ?")
                params.append(end_date)
            if source:
                where_conditions.append("source = ?")
                params.append(source)

            where_clause = ""
            if where_conditions:
                where_clause = "WHERE " + " AND ".join(where_conditions)

            # è·å–æ€»æ•°
            count_params = params.copy()
            async with db.execute(
                f"SELECT COUNT(*) as count FROM hot_topics {where_clause}",
                count_params
            ) as cursor:
                row = await cursor.fetchone()
                total = row["count"]

            # è·å–åˆ†é¡µæ•°æ®
            query_params = params.copy()
            query_params.extend([limit, offset])
            async with db.execute(f'''
                SELECT * FROM hot_topics
                {where_clause}
                ORDER BY created_at DESC, heat DESC
                LIMIT ? OFFSET ?
            ''', query_params) as cursor:
                rows = await cursor.fetchall()

            for r in rows:
                topics.append({
                    "id": r['id'],
                    "title": r['title'],
                    "link": r['link'],
                    "source": r['source'],
                    "heat": r['heat'],
                    "tags": json.loads(r['tags']) if r['tags'] else [],
                    "comment": r['comment'],
                    "created_at": r['created_at'],
                    "category_id": r.get('category_id'),
                    "matched_keyword": r.get('matched_keyword')
                })

    except Exception as e:
        add_log('error', f'æŒ‰åˆ†ç±»è·å–çƒ­ç‚¹å¤±è´¥: {e}')

    return {
        "topics": topics,
        "total": total,
        "offset": offset,
        "limit": limit
    }


# ==================== åŸå§‹æ–°é—»è¡¨ (raw_news) æ“ä½œ ====================

async def save_raw_news_to_db(news_list: List[Dict], category_id: int = None) -> int:
    """
    ä¿å­˜çˆ¬å–çš„åŸå§‹æ–°é—»åˆ°æ•°æ®åº“ï¼ˆå¼‚æ­¥ï¼‰
    ä½¿ç”¨ INSERT OR IGNORE é¿å…é‡å¤

    Args:
        news_list: æ–°é—»åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« title, link, source ç­‰
        category_id: å¯é€‰çš„åˆ†ç±»ID

    Returns:
        ä¿å­˜çš„è®°å½•æ•°
    """
    count = 0
    try:
        async with get_db() as db:
            for news in news_list:
                try:
                    await db.execute('''
                        INSERT OR IGNORE INTO raw_news (
                            title, link, source, category_id, created_at
                        ) VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
                    ''', (
                        news.get('title', ''),
                        news.get('link', ''),
                        news.get('source', ''),
                        category_id
                    ))
                    if db.total_changes > 0:
                        count += 1
                except Exception as e:
                    add_log('warning', f'ä¿å­˜å•æ¡æ–°é—»å¤±è´¥: {e}')

            await db.commit()
            add_log('success', f'åŸå§‹æ–°é—»ä¿å­˜å®Œæˆï¼Œæ–°å¢ {count} æ¡')

    except Exception as e:
        add_log('error', f'æ‰¹é‡ä¿å­˜åŸå§‹æ–°é—»å¤±è´¥: {e}')

    return count


async def get_unanalyzed_news(limit: int = 50, max_fail_count: int = 3) -> List[Dict]:
    """
    è·å–æœªåˆ†æçš„æˆ–å¯é‡è¯•çš„æ–°é—»

    Args:
        limit: è·å–æ•°é‡é™åˆ¶
        max_fail_count: æœ€å¤§å¤±è´¥æ¬¡æ•°é™åˆ¶

    Returns:
        æœªåˆ†æçš„æ–°é—»åˆ—è¡¨
    """
    news_list = []
    try:
        async with get_db() as db:
            
            async with db.execute('''
                SELECT * FROM raw_news
                WHERE analyzed = 0
                  AND (skip_reason IS NULL OR skip_reason = '')
                  AND analyze_fail_count <= ?
                  AND created_at > datetime('now', '-7 days')
                ORDER BY created_at DESC
                LIMIT ?
            ''', (max_fail_count, limit)) as cursor:
                rows = await cursor.fetchall()

                for r in rows:
                    news_list.append({
                        'id': r['id'],
                        'title': r['title'],
                        'link': r['link'],
                        'source': r['source'],
                        'category_id': r['category_id'],
                        'analyze_fail_count': r['analyze_fail_count']
                    })

    except Exception as e:
        add_log('error', f'è·å–æœªåˆ†ææ–°é—»å¤±è´¥: {e}')

    return news_list


async def update_news_analysis(news_id: int, ai_score: float, ai_comment: str,
                               analyzed: bool = True, skip_reason: str = None) -> bool:
    """
    æ›´æ–°æ–°é—»çš„åˆ†æç»“æœ

    Args:
        news_id: æ–°é—»ID
        ai_score: AIè¯„åˆ† (0-10)
        ai_comment: AIè¯„è®º
        analyzed: æ˜¯å¦åˆ†æå®Œæˆ
        skip_reason: è·³è¿‡åŸå› ï¼ˆå¦‚æœåˆ†æå¤±è´¥ï¼‰

    Returns:
        æ˜¯å¦æ›´æ–°æˆåŠŸ
    """
    try:
        async with get_db() as db:
            if analyzed:
                await db.execute('''
                    UPDATE raw_news
                    SET analyzed = 1,
                        ai_score = ?,
                        ai_comment = ?,
                        last_analyzed_at = CURRENT_TIMESTAMP,
                        skip_reason = NULL
                    WHERE id = ?
                ''', (ai_score, ai_comment, news_id))
            else:
                # å¢åŠ å¤±è´¥è®¡æ•°
                await db.execute('''
                    UPDATE raw_news
                    SET analyze_fail_count = analyze_fail_count + 1,
                        skip_reason = ?,
                        last_analyzed_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                ''', (skip_reason, news_id))

            await db.commit()
            return True

    except Exception as e:
        add_log('error', f'æ›´æ–°æ–°é—»åˆ†æå¤±è´¥: {e}')
        return False


async def get_top_scoring_news(hours: int = 48, limit: int = 50,
                                 min_score: float = 0.0) -> List[Dict]:
    """
    è·å–æŒ‡å®šæ—¶é—´å†…è¯„åˆ†æœ€é«˜çš„æ–°é—»

    Args:
        hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶
        min_score: æœ€ä½åˆ†æ•°è¦æ±‚

    Returns:
        è¯„åˆ†æœ€é«˜çš„æ–°é—»åˆ—è¡¨
    """
    news_list = []
    try:
        async with get_db() as db:
            
            async with db.execute('''
                SELECT id, title, link, source,
                       ai_score, ai_comment, category_id, created_at
                FROM raw_news
                WHERE analyzed = 1
                  AND ai_score >= ?
                  AND created_at > datetime('now', '-' || ? || ' hours')
                ORDER BY ai_score DESC, created_at DESC
                LIMIT ?
            ''', (min_score, hours, limit)) as cursor:
                rows = await cursor.fetchall()

                for r in rows:
                    news_list.append({
                        'id': r['id'],
                        'title': r['title'],
                        'link': r['link'],
                        'source': r['source'],
                        'ai_score': r['ai_score'],
                        'ai_comment': r['ai_comment'],
                        'category_id': r['category_id'],
                        'created_at': r['created_at']
                    })

    except Exception as e:
        add_log('error', f'è·å–é«˜è¯„åˆ†æ–°é—»å¤±è´¥: {e}')

    return news_list


async def save_hot_topics(topics: List[Dict]) -> int:
    """
    ä¿å­˜ç²¾é€‰çš„çƒ­ç‚¹æ–°é—»åˆ° hot_topics è¡¨
    å…ˆæ¸…ç©ºæ—§æ•°æ®ï¼Œå†æ’å…¥æ–°æ•°æ®

    Args:
        topics: ç²¾é€‰çš„çƒ­ç‚¹è¯é¢˜åˆ—è¡¨ï¼ŒåŒ…å« ai_score, ai_comment ç­‰å­—æ®µ

    Returns:
        ä¿å­˜çš„è®°å½•æ•°
    """
    count = 0
    try:
        async with get_db() as db:
            # æ¸…ç©ºæ—§çš„ hot_topics
            await db.execute('DELETE FROM hot_topics')

            # æ’å…¥æ–°çš„çƒ­ç‚¹è¯é¢˜
            for topic in topics:
                await db.execute('''
                    INSERT INTO hot_topics (
                        title, link, source, ai_score, ai_comment,
                        category_id, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                ''', (
                    topic.get('title', ''),
                    topic.get('link', ''),
                    topic.get('source', ''),
                    topic.get('ai_score'),
                    topic.get('ai_comment', ''),
                    topic.get('category_id')
                ))
                count += 1

            await db.commit()
            add_log('success', f'çƒ­ç‚¹è¯é¢˜æ›´æ–°å®Œæˆï¼Œå…± {count} æ¡')

    except Exception as e:
        add_log('error', f'ä¿å­˜çƒ­ç‚¹è¯é¢˜å¤±è´¥: {e}')

    return count


async def get_raw_news_stats() -> Dict:
    """
    è·å–åŸå§‹æ–°é—»ç»Ÿè®¡ä¿¡æ¯

    Returns:
        ç»Ÿè®¡æ•°æ®å­—å…¸
    """
    stats = {
        'total': 0,
        'analyzed': 0,
        'unanalyzed': 0,
        'skipped': 0,
        'avg_score': 0.0
    }
    try:
        async with get_db() as db:
            async with db.execute('SELECT COUNT(*) as count FROM raw_news') as cursor:
                stats['total'] = (await cursor.fetchone())['count']

            async with db.execute('''
                SELECT COUNT(*) as count FROM raw_news WHERE analyzed = 1
            ''') as cursor:
                stats['analyzed'] = (await cursor.fetchone())['count']

            async with db.execute('''
                SELECT COUNT(*) as count FROM raw_news
                WHERE analyzed = 0 AND skip_reason IS NOT NULL AND skip_reason != ''
            ''') as cursor:
                stats['skipped'] = (await cursor.fetchone())['count']

            stats['unanalyzed'] = stats['total'] - stats['analyzed'] - stats['skipped']

            async with db.execute('''
                SELECT AVG(ai_score) as avg_score FROM raw_news
                WHERE analyzed = 1 AND ai_score IS NOT NULL
            ''') as cursor:
                row = await cursor.fetchone()
                stats['avg_score'] = row['avg_score'] if row['avg_score'] else 0.0

    except Exception as e:
        add_log('error', f'è·å–åŸå§‹æ–°é—»ç»Ÿè®¡å¤±è´¥: {e}')

    return stats

